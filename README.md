# Taller 4 â€“ OrquestaciÃ³n con Airflow y Despliegue de API para Inferencia

## Integrantes
- **Yibby GonzÃ¡lez**  
- **SebastiÃ¡n Ruiz**  
- **AdriÃ¡n TÃ©llez**

---

## ðŸŽ¯ Objetivo
El objetivo de este taller es implementar un **pipeline completo de Machine Learning** utilizando **Apache Airflow**, desde la ingesta de datos hasta el despliegue de un modelo entrenado mediante un servicio de inferencia expuesto con **FastAPI**.  

---

## ðŸ“¦ Arquitectura de la soluciÃ³n
El proyecto levanta mÃºltiples servicios en **Docker Compose**:

- **Postgres** â†’ Base de datos de metadatos de Airflow.  
- **MariaDB** â†’ Base de datos para almacenar los datos de *penguins*.  
- **Redis** â†’ Broker para el scheduler de Airflow.  
- **Airflow Webserver** â†’ Interfaz web de Airflow (DAGs y monitoreo).  
- **Airflow Scheduler** â†’ Encargado de planificar y ejecutar las tareas.  
- **Airflow Worker** â†’ Ejecutor de las tareas del DAG.  
- **API FastAPI** â†’ Servicio que carga el modelo entrenado y permite realizar inferencia.  

---

## âš™ï¸ Evidencia de ejecuciÃ³n

Al levantar el proyecto con `docker compose up --build`, se puede verificar con `docker ps` los servicios corriendo:

```
NAME                                         IMAGE                                      COMMAND                  SERVICE             CREATED         STATUS                   PORTS
penguins-airflow-final-airflow-scheduler-1   penguins-airflow-final-airflow-scheduler   "/usr/bin/dumb-init â€¦"   airflow-scheduler   9 minutes ago   Up 5 minutes             8080/tcp
penguins-airflow-final-airflow-webserver-1   penguins-airflow-final-airflow-webserver   "/usr/bin/dumb-init â€¦"   airflow-webserver   9 minutes ago   Up 3 minutes             0.0.0.0:8081->8080/tcp, [::]:8081->8080/tcp
penguins-airflow-final-airflow-worker-1      penguins-airflow-final-airflow-worker      "/usr/bin/dumb-init â€¦"   airflow-worker      9 minutes ago   Up 3 minutes             8080/tcp
penguins-airflow-final-api-1                 penguins-airflow-final-api                 "uvicorn main:app --â€¦"   api                 9 minutes ago   Up 3 minutes             0.0.0.0:8080->8000/tcp, [::]:8080->8000/tcp
penguins-airflow-final-penguins-db-1         mariadb:11                                 "docker-entrypoint.sâ€¦"   penguins-db         9 minutes ago   Up 9 minutes (healthy)   0.0.0.0:3306->3306/tcp, [::]:3306->3306/tcp
penguins-airflow-final-postgres-1            postgres:15-alpine                         "docker-entrypoint.sâ€¦"   postgres            9 minutes ago   Up 9 minutes (healthy)   0.0.0.0:5432->5432/tcp, [::]:5432->5432/tcp
penguins-airflow-final-redis-1               redis:7-alpine                             "docker-entrypoint.sâ€¦"   redis               9 minutes ago   Up 9 minutes             6379/tcp
```

---

## ðŸš€ EjecuciÃ³n del pipeline

1. **Levantar el entorno**  
   ```bash
   docker compose up --build
   ```

2. **Acceder a Airflow**  
   - URL: [http://localhost:8081](http://localhost:8081)  
   - Usuario: `admin`  
   - ContraseÃ±a: `admin`

3. **Ejecutar el DAG `penguins_etl_train`**  
   Este DAG realiza las siguientes tareas:  
   - Borrar contenido de la base de datos.  
   - Cargar los datos de *penguins* sin preprocesar.  
   - Realizar el preprocesamiento.  
   - Entrenar un modelo de clasificaciÃ³n y guardarlo en `/models/model.pkl`.  

---

## ðŸ§ª Consumo de la API de inferencia

Una vez entrenado el modelo, el servicio de API en **FastAPI** queda disponible en:  
ðŸ‘‰ [http://localhost:8080](http://localhost:8080)

### 1. Probar que el servicio estÃ¡ activo
```bash
curl http://localhost:8080/
```

### 2. Realizar una predicciÃ³n
```bash
curl -X POST http://localhost:8080/predict   -H 'Content-Type: application/json'   -d '{
        "island": "Torgersen",
        "bill_length_mm": 39.1,
        "bill_depth_mm": 18.7,
        "flipper_length_mm": 181,
        "body_mass_g": 3750,
        "sex": "Male"
      }'
```

### 3. Respuesta esperada
```json
{
  "prediction": "Adelie",
  "accuracy": 0.97
}
```

---

## âœ… Conclusiones
- Se logrÃ³ implementar un **pipeline de ML orquestado con Airflow**.  
- Los datos fueron procesados y almacenados en MariaDB.  
- Se entrenÃ³ un modelo que luego se expone como **servicio de inferencia con FastAPI**.  
- Todo el ecosistema corre de manera integrada en **Docker Compose**.
